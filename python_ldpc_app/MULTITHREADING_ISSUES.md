# Проблемы производительности многопоточности

## Критические проблемы

### 1. GIL (Global Interpreter Lock) - РЕШЕНО ✅
**Проблема:** Python использует GIL, который ограничивает параллельное выполнение CPU-bound задач в потоках. 
`ThreadPoolExecutor` не может эффективно использовать несколько ядер процессора для CPU-intensive операций (декодирование).

**Решение:** ✅ ИСПРАВЛЕНО - Используется `ProcessPoolExecutor` вместо `ThreadPoolExecutor` для CPU-bound задач.

**Местоположение:** `main.py:327` - `ProcessPoolExecutor(max_workers=args.threads)`

**Примечание:** 
- Все объекты, передаваемые в процессы, должны быть pickle-able (scipy.sparse матрицы поддерживают pickle)
- Для Windows требуется `if __name__ == '__main__'` (уже реализовано)
- Lock не нужен, так как каждый процесс имеет свою память

### 2. Использование math.tanh и math.atanh вместо numpy
**Проблема:** `math.tanh()` и `math.atanh()` медленнее, чем numpy версии, особенно при множественных вызовах.

**Местоположение:** `spa_decoder.py:121, 128`

**Решение:** Использовать `np.tanh()` и `np.arctanh()` для векторных операций.

### 3. Создание словарей M и E в каждом decode()
**Проблема:** Словари M и E создаются заново в каждом вызове `decode()`, что может быть медленно для больших матриц.

**Местоположение:** `spa_decoder.py:70, 74`

**Решение:** Переиспользовать структуры или использовать предварительно выделенные массивы.

### 4. Использование random.gauss в channel.process()
**Проблема:** `random.gauss()` может быть узким местом из-за GIL, особенно при большом количестве потоков.

**Местоположение:** `channel.py:42`

**Решение:** Использовать numpy.random для генерации случайных чисел (освобождает GIL).

### 5. Неоптимальный размер батчей
**Проблема:** Размер батча `max(1, args.threads)` может быть слишком маленьким, что приводит к частым блокировкам.

**Местоположение:** `main.py:344`

**Решение:** Увеличить размер батча до разумного значения (например, 50-100).

### 6. Передача args в каждый поток
**Проблема:** Передача объекта `args` в каждый поток создает overhead из-за сериализации/копирования.

**Местоположение:** `main.py:336`

**Решение:** Передавать только необходимые флаги как простые типы.

## Рекомендации по оптимизации

### Приоритет 1 (Критично):
1. Заменить `ThreadPoolExecutor` на `ProcessPoolExecutor` для CPU-bound задач
2. Использовать numpy для математических операций (tanh, atanh)

### Приоритет 2 (Важно):
3. Оптимизировать генерацию случайных чисел (numpy.random)
4. Увеличить размер батчей для уменьшения lock contention
5. Передавать только необходимые данные в потоки

### Приоритет 3 (Опционально):
6. Переиспользовать структуры данных в decode()
7. Использовать более эффективные структуры данных
